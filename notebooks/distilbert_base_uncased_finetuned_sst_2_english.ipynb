{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcNdrbIhCLv0",
        "outputId": "719ebb4c-7238-4e7e-86e1-17028d73a7f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 40.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 37.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###With pipeline using pretrained model\n",
        "You should use tokenizer,and model class In this example Autotokenizer, AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "bcEKHSpGG_hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer,AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "uCDL7g9VDB8B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "nWVU3JsvDIyv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###You should specify the model name,and use \"from_pretrained\" class initialization function. Then in pipeline, you should define the task like text-classification in that example,and the model name"
      ],
      "metadata": {
        "id": "dOPFMUNhIsJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_name=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model=AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "classifier=pipeline(\"text-classification\",model=model_name)"
      ],
      "metadata": {
        "id": "Exsmmkq1DL_T"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Meta plans the world’s fastest supercomputer for AI\"\n",
        "reg=classifier(text)\n",
        "print(reg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz8eb8q0Dfpv",
        "outputId": "3663d1bd-19e6-4b70-fd6d-34ed8683a974"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9959184527397156}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###If you see tokens and batch output."
      ],
      "metadata": {
        "id": "0mwSGBtoK6tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=tokenizer.tokenize(text)\n",
        "token_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
        "input_ids=tokenizer(text)"
      ],
      "metadata": {
        "id": "sSZt30O4Fa4z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-ol4Mi_Izhu",
        "outputId": "da9b380f-47ce-447a-98ad-674376866391"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[18804,\n",
              " 3488,\n",
              " 1996,\n",
              " 2088,\n",
              " 1521,\n",
              " 1055,\n",
              " 7915,\n",
              " 3565,\n",
              " 9006,\n",
              " 18780,\n",
              " 2121,\n",
              " 2005,\n",
              " 9932]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=text\n",
        "batch=tokenizer(X_train,padding=True,truncation=True,max_length=512,return_tensors=\"pt\")\n",
        "print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP2DusjpI0bG",
        "outputId": "cdece155-390f-4a8a-8bf4-a4c07dbca47a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101, 18804,  3488,  1996,  2088,  1521,  1055,  7915,  3565,  9006,\n",
            "         18780,  2121,  2005,  9932,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs=model(**batch,labels=torch.tensor([0]))\n",
        "  print(outputs)\n",
        "  predictions=F.softmax(outputs.logits,dim=1)\n",
        "  print(predictions)\n",
        "  labels=torch.argmax(predictions,dim=1)\n",
        "  print(labels)\n",
        "  labels=[model.config.id2label[label_id] for label_id in labels.tolist()]\n",
        "  print(labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bJeEeCdJ3kv",
        "outputId": "6f6dffd9-316e-42c7-9a9f-a37728b9cd9b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=tensor(5.5013), logits=tensor([[-2.7214,  2.7758]]), hidden_states=None, attentions=None)\n",
            "tensor([[0.0041, 0.9959]])\n",
            "tensor([1])\n",
            "['POSITIVE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qvyorn3zQG70"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}